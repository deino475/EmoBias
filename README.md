# EmoBias

## Description

EmoBias is a Python package that allows individuals to assess whether an LLM fine-tuned to perform either single-label, multi-label, or entailment based emotion detection is biased when prefixed with stereotypical gendered or racial names.


## How To Use


## Influential Works
These papers guided my development of this library:
- Automating Bias Testing of LLMs
- Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems
- Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models
- LangTest: A comprehensive evaluation library for custom LLM and NLP models
- Natural Language Inference Prompts for Zero-shot Emotion Classification in Text across Corpora
- XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection


## Cite Us
If you use this library to audit a model for bias in emotion detection, please use this citation:
